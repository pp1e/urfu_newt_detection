import torch
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm import tqdm
import matplotlib.pyplot as plt

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
MODEL_PATH = Path("models/unet_belly_fine.pt")
DATASETS = ["dataset/triton_karelina", "dataset/rebristii_triton"]
OUT_ROOT = Path("predictions/belly_scratch_all")
OUT_ROOT.mkdir(parents=True, exist_ok=True)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
IMG_SIZE = 512
THRESHOLD = 0.35  # –º—è–≥–∫–∏–π –ø–æ—Ä–æ–≥ 0.3‚Äì0.4 –¥–∞—ë—Ç –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω—ã–µ –∫–æ–Ω—Ç—É—Ä—ã

# === –ú–û–î–ï–õ–¨ ===
print(f"üß† –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {MODEL_PATH.name}")
model = smp.Unet(
    encoder_name="resnet34",
    in_channels=3,
    classes=1,
    encoder_weights="imagenet",
)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.to(DEVICE)
model.eval()

# === –¢–†–ê–ù–°–§–û–†–ú ===
transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.Normalize(mean=(0, 0, 0), std=(1, 1, 1)),
    ToTensorV2(),
])

# === –§–£–ù–ö–¶–ò–Ø –ü–†–ï–î–ò–ö–¢–ê ===
def predict_image(image_path: Path, out_dir: Path):
    img = np.array(Image.open(image_path).convert("RGB"))
    orig_h, orig_w = img.shape[:2]

    transformed = transform(image=img)
    tensor = transformed["image"].unsqueeze(0).to(DEVICE, dtype=torch.float32)

    with torch.no_grad():
        pred = torch.sigmoid(model(tensor))[0, 0].cpu().numpy()

    mask = (pred > THRESHOLD).astype(np.uint8) * 255
    mask_resized = cv2.resize(mask, (orig_w, orig_h))

    # === –°–û–ó–î–ê–Å–ú –û–í–ï–†–õ–ï–ô ===
    overlay = img.copy()
    color_mask = np.zeros_like(img)
    color_mask[..., 1] = 255  # –∑–µ–ª—ë–Ω—ã–π –∫–∞–Ω–∞–ª
    overlay = cv2.addWeighted(color_mask, 0.4, overlay, 0.6, 0)
    overlay[mask_resized == 0] = img[mask_resized == 0]

    mask_path = out_dir / f"{image_path.stem}_mask.png"
    overlay_path = out_dir / f"{image_path.stem}_overlay.jpg"

    cv2.imwrite(str(mask_path), mask_resized)
    cv2.imwrite(str(overlay_path), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))
    return img, overlay, mask_resized


# === –ü–†–û–•–û–î –ü–û –í–°–ï–ú –ü–ê–ü–ö–ê–ú ===
for ds_root in DATASETS:
    ds_root = Path(ds_root)
    ds_name = ds_root.name
    print(f"\nüìÇ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç: {ds_name}")

    for subfolder in sorted(ds_root.iterdir()):
        if not subfolder.is_dir():
            continue

        imgs = sorted(list(subfolder.glob("*.JPG"))) + sorted(list(subfolder.glob("*.jpg")))
        if not imgs:
            continue

        out_dir = OUT_ROOT / ds_name / subfolder.name
        out_dir.mkdir(parents=True, exist_ok=True)

        all_overlays = []

        print(f"  üî∏ {subfolder.name} ({len(imgs)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
        for img_path in tqdm(imgs, desc=f"{ds_name}/{subfolder.name}"):
            _, overlay, _ = predict_image(img_path, out_dir)
            # —É–º–µ–Ω—å—à–∏—Ç—å –¥–ª—è –∫–æ–ª–ª–∞–∂–∞
            overlay_small = cv2.resize(overlay, (256, 256))
            all_overlays.append(overlay_small)

        # === –°–û–ó–î–ê–Å–ú –ö–û–õ–õ–ê–ñ ===
        if all_overlays:
            cols = min(5, len(all_overlays))
            rows = int(np.ceil(len(all_overlays) / cols))
            canvas = np.ones((rows * 256, cols * 256, 3), dtype=np.uint8) * 255

            for idx, ov in enumerate(all_overlays):
                r, c = divmod(idx, cols)
                y1, y2 = r * 256, (r + 1) * 256
                x1, x2 = c * 256, (c + 1) * 256
                canvas[y1:y2, x1:x2] = ov

            collage_path = out_dir / f"preview_{subfolder.name}.png"
            cv2.imwrite(str(collage_path), cv2.cvtColor(canvas, cv2.COLOR_RGB2BGR))
            print(f"  üì∏ –ö–æ–ª–ª–∞–∂ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {collage_path.relative_to(OUT_ROOT)}")

print(f"\n‚úÖ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {OUT_ROOT}")
